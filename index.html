<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Handwritten Math Expression Recognition</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background-color: #fff;
    }
    canvas {
      border: 1px solid black;
    }
    #prediction {
      position: absolute;
      top: 10px;
      left: 10px;
      font-size: 24px;
      color: black;
    }
  </style>
</head>
<body>
  <div id="prediction">Loading model...</div>
  <canvas id="canvas"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script>
    let model;
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const predictionDisplay = document.getElementById('prediction');
    let drawing = false;
    let strokes = [];

    // Set canvas size to full screen
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;

    async function loadModel() {
      try {
        const model = await tf.loadGraphModel('https://raw.githubusercontent.com/Jaquoya/Models/refs/heads/main/model/model.json');
        console.log('Model loaded successfully');
        predictionDisplay.textContent = 'Draw a symbol';
      } catch (error) {
        console.error('Error loading model:', error);
        predictionDisplay.textContent = 'Failed to load model';
      }
    }

    // Draw the stroke on canvas
    function drawStroke(stroke) {
      ctx.beginPath();
      ctx.moveTo(stroke[0].x, stroke[0].y);
      for (let i = 1; i < stroke.length; i++) {
        ctx.lineTo(stroke[i].x, stroke[i].y);
      }
      ctx.stroke();
    }

    // Handle mouse events for drawing on canvas
    canvas.addEventListener('mousedown', (event) => {
      drawing = true;
      strokes.push([{x: event.clientX, y: event.clientY}]);
    });

    canvas.addEventListener('mousemove', (event) => {
      if (drawing) {
        const currentStroke = strokes[strokes.length - 1];
        currentStroke.push({x: event.clientX, y: event.clientY});
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        strokes.forEach(stroke => drawStroke(stroke));
      }
    });

    canvas.addEventListener('mouseup', () => {
      drawing = false;
      recognizeDrawing();
    });

    // Recognize the drawing after it stops
    async function recognizeDrawing() {
      if (strokes.length > 0) {
        const canvasImage = await getCanvasImage();
        const inputTensor = tf.browser.fromPixels(canvasImage)
          .resizeNearestNeighbor([64, 64])
          .mean(2) // Convert to grayscale
          .expandDims(2)
          .expandDims(0)
          .toFloat();
        
        const prediction = await model.predict(inputTensor);
        const predictedClass = prediction.argMax(-1).dataSync()[0];
        predictionDisplay.textContent = `Predicted: ${predictedClass}`;
      }
    }

    // Get the canvas image for recognition
    function getCanvasImage() {
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = canvas.width;
      tempCanvas.height = canvas.height;
      const tempCtx = tempCanvas.getContext('2d');
      tempCtx.putImageData(imageData, 0, 0);
      return tempCanvas;
    }

    // Load the model when the page loads
    window.onload = loadModel;
  </script>
</body>
</html>
