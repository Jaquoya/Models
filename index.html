<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Handwritten Math Expression Recognition</title>
  <style>
    canvas {
      border: 1px solid black;
    }
  </style>
</head>
<body>
  <h1>Draw a Math Expression</h1>
  <canvas id="canvas" width="256" height="256"></canvas> <!-- Larger canvas for drawing -->
  <br>
  <button onclick="clearCanvas()">Clear Canvas</button>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- TensorFlow.js -->
  <script>
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const modelURL = 'https://raw.githubusercontent.com/Jaquoya/Models/main/model.json'; // Correct model URL
    let model;

    // Load the model
    async function loadModel() {
      try {
        model = await tf.loadGraphModel(modelURL);
        console.log('Model loaded successfully');

        // Print the model's input shape
        console.log('Model input shape:', model.inputs[0].shape);
      } catch (error) {
        console.error('Error loading model:', error);
      }
    }

    // Resize and preprocess the image for the model
    async function preprocessCanvas() {
      // Create a temporary canvas to resize the drawing
      const tempCanvas = document.createElement('canvas');
      const tempCtx = tempCanvas.getContext('2d');

      // Set the target size to 64x64
      tempCanvas.width = 64;
      tempCanvas.height = 64;

      // Draw the current canvas image to the temp canvas with resizing
      tempCtx.drawImage(canvas, 0, 0, 64, 64);

      // Get image data from the resized canvas
      const imageData = tempCtx.getImageData(0, 0, 64, 64);
      const pixels = imageData.data;

      // Convert to grayscale (average RGB values)
      const grayscaleData = [];
      for (let i = 0; i < pixels.length; i += 4) {
        const r = pixels[i];
        const g = pixels[i + 1];
        const b = pixels[i + 2];
        const gray = (r + g + b) / 3; // Averaging RGB for grayscale
        grayscaleData.push(gray);
      }

      // Convert to a Tensor and normalize it to [0, 1]
      const tensor = tf.tensor(grayscaleData, [64, 64, 1], 'float32');
      const normalizedTensor = tensor.div(tf.scalar(255)); // Normalize to [0, 1]

      return normalizedTensor;
    }

    // Recognize the drawing and make a prediction
    async function recognizeDrawing() {
      if (model) {
        const inputTensor = await preprocessCanvas();
        const prediction = await model.predict(inputTensor.expandDims(0)); // Add batch dimension

        // Process the prediction (example: just log the result)
        prediction.print();
        alert('Prediction made! Check the console for output.');
      } else {
        console.error('Model not loaded yet!');
      }
    }

    // Clear the canvas for new drawings
    function clearCanvas() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    // Setup the drawing functionality
    let drawing = false;
    canvas.addEventListener('mousedown', (e) => {
      drawing = true;
      ctx.beginPath();
      ctx.moveTo(e.offsetX, e.offsetY);
    });

    canvas.addEventListener('mousemove', (e) => {
      if (drawing) {
        ctx.lineTo(e.offsetX, e.offsetY);
        ctx.stroke();
      }
    });

    canvas.addEventListener('mouseup', () => {
      drawing = false;
      recognizeDrawing(); // Trigger recognition once drawing stops
    });

    // Load the model when the page loads
    window.onload = loadModel;
  </script>
</body>
</html>
